<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Hailey Orton" />
    
    <link rel="shortcut icon" type="image/x-icon" href="../../img/favicon.ico">
    <title>Project 2: Modeling, Testing, and Predicting</title>
    <meta name="generator" content="Hugo 0.83.1" />
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="../../css/main.css" />
    <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" />
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,400,200bold,400old" />
    
    <!--[if lt IE 9]>
			<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
			<script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
		<![endif]-->

    
  </head>

  <body>
    <div id="wrap">
      
      <nav class="navbar navbar-default">
  <div class="container">
    <div class="navbar-header">
      <a class="navbar-brand" href="../../"><i class="fa fa-home"></i></a>
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <div class="navbar-collapse collapse" id="navbar">
      <ul class="nav navbar-nav navbar-right">
      
        
        <li><a href="../../post/">BLOG</a></li>
        
        <li><a href="../../projects/">PROJECTS</a></li>
        
        <li><a href="../../resume/">RESUME</a></li>
        
      
      </ul>
    </div>
  </div>
</nav>

      <div class="container">
        <div class="blog-post">
          <h3>
            <strong><a href="../../project/project2/">Project 2: Modeling, Testing, and Predicting</a></strong>
          </h3>
        </div>
 
<div class="blog-title">
          <h4>
         August 5, 2021 
            &nbsp;&nbsp;
            
          </h4>
        </div>

        <div class="panel panel-default">
          <div class="panel-body">
            <div class="blogpost">
              


<div id="guidelines-and-rubric" class="section level2">
<h2>Guidelines and Rubric</h2>
<ul>
<li><strong>0. (5 pts)</strong> Introduce your dataset and each of your variables (or just your main variables if you have lots) in a paragraph. What are they measuring? How many observations?</li>
</ul>
<p>My dataset is exploring arrests regarding marijuana possession. The dataset explores race, employment, sex, citizenship, age, previous arrests, whether they were released, and the year of the arrest. The dataset may be at least somewhat out of date, as it lists race as “colour.” The dataset has 5226 observations. I am most interested in seeing whether there is a correlation with race or citizenship, and whether the individual was released.</p>
<ul>
<li><strong>1. (15 pts)</strong> Perform a MANOVA testing whether any of your numeric variables (or a subset of them, if including them all is unreasonable or doesn’t make sense) show a mean difference across levels of one of your categorical variables (3). If they do, perform univariate ANOVAs to find response(s) showing a mean difference across groups (3), and perform post-hoc t tests to find which groups differ (3). Discuss the number of tests you have performed, calculate the probability of at least one type I error (if unadjusted), and adjust the significance level accordingly (bonferroni correction) before discussing significant differences (3). Briefly discuss some of the MANOVA assumptions and whether or not they are likely to have been met here (no need for anything too in-depth) (2).</li>
</ul>
<pre class="r"><code>##MANOVA
Arrests &lt;- read.csv(&quot;Arrests.csv&quot;)
manova_test&lt;-manova(cbind(age, checks)~citizen, data=Arrests)
summary(manova_test)</code></pre>
<pre><code>## Df Pillai approx F num Df den Df Pr(&gt;F)
## citizen 1 0.005886 15.462 2 5223 2.017e-07 ***
## Residuals 5224
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>summary.aov(manova_test)</code></pre>
<pre><code>## Response age :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## citizen 1 1910 1909.64 27.754 1.433e-07 ***
## Residuals 5224 359441 68.81
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Response checks :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## citizen 1 14.4 14.4073 6.0869 0.01365 *
## Residuals 5224 12364.8 2.3669
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>Arrests%&gt;%group_by(citizen)%&gt;%summarize(mean(checks),mean(age))</code></pre>
<pre><code>## # A tibble: 2 x 3
##   citizen `mean(checks)` `mean(age)`
##   &lt;fct&gt;            &lt;dbl&gt;       &lt;dbl&gt;
## 1 No                1.76        25.3
## 2 Yes               1.61        23.6</code></pre>
<pre class="r"><code>pairwise.t.test(Arrests$age,Arrests$citizen,p.adj=&quot;none&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  Arrests$age and Arrests$citizen 
## 
##     No     
## Yes 1.4e-07
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>pairwise.t.test(Arrests$checks,Arrests$citizen,p.adj=&quot;none&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  Arrests$checks and Arrests$citizen 
## 
##     No   
## Yes 0.014
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>1-.95^2</code></pre>
<pre><code>## [1] 0.0975</code></pre>
<pre class="r"><code>.05/2</code></pre>
<pre><code>## [1] 0.025</code></pre>
<p><em>I found that individually, a persons age and the number of previous arrests makes a significant difference on whether or not they are a citizen. Additionally, the two variables when taken into consideration together also make a significant difference on whether or not the person is a citizen. The t tests confirm that citizen status has a significant effect on the persons age and number of previous checks. I ran a two t tests, so there is a 9.75% chance of some sort of type 1 error, and the bonferroni correction is .025. The data comes from a small sample area (Toronto), so the data is good for random sampling and concluding data from this area, but may not be applicable elsewhere.</em></p>
<ul>
<li><strong>2. (10 pts)</strong> Perform some kind of randomization test on your data (that makes sense). The statistic can be anything you want (mean difference, correlation, F-statistic/ANOVA, chi-squared), etc. State null and alternative hypotheses, perform the test, and interpret the results (7). Create a plot visualizing the null distribution and the test statistic (3).</li>
</ul>
<pre class="r"><code>noncitizens &lt;- Arrests %&gt;% filter(citizen %in% c(&quot;No&quot;)) %&gt;% select(checks)
noncitizens &lt;- as.vector(t(noncitizens))
citizens &lt;- Arrests %&gt;% filter(citizen %in% c(&quot;Yes&quot;)) %&gt;% select(checks)
citizens &lt;- as.vector(t(citizens))

citizenry_checks &lt;-data.frame(citizen=c(rep(&quot;citizens&quot;,4455),rep(&quot;noncitizens&quot;,771)),checks=c(citizens,noncitizens))
head(citizenry_checks)</code></pre>
<pre><code>##    citizen checks
## 1 citizens      3
## 2 citizens      3
## 3 citizens      3
## 4 citizens      1
## 5 citizens      1
## 6 citizens      0</code></pre>
<pre class="r"><code>ggplot(citizenry_checks, aes(checks,fill=citizen))+geom_histogram(bins=5)+  facet_wrap(~citizen,ncol=2)+theme(legend.position=&quot;none&quot;)</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-2-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>citizenry_checks %&gt;% group_by(citizen)%&gt;%
  summarize(means=mean(checks))%&gt;%summarize(`mean_diff:`=diff(means))</code></pre>
<pre><code>## # A tibble: 1 x 1
##   `mean_diff:`
##          &lt;dbl&gt;
## 1        0.148</code></pre>
<pre class="r"><code>head(perm1&lt;-data.frame(checks=citizenry_checks$checks,citizen=sample(citizenry_checks$citizen)))</code></pre>
<pre><code>##   checks     citizen
## 1      3    citizens
## 2      3    citizens
## 3      3 noncitizens
## 4      1    citizens
## 5      1    citizens
## 6      0    citizens</code></pre>
<pre class="r"><code>perm1%&gt;%group_by(citizen)%&gt;%
  summarize(means=mean(checks))%&gt;%summarize(`mean_diff:`=diff(means))</code></pre>
<pre><code>## # A tibble: 1 x 1
##   `mean_diff:`
##          &lt;dbl&gt;
## 1       0.0248</code></pre>
<pre class="r"><code>Arrests %&gt;% group_by(citizen)%&gt;%
  summarize(means=mean(checks))%&gt;%summarize(`mean_diff:`=diff(means))</code></pre>
<pre><code>## # A tibble: 1 x 1
##   `mean_diff:`
##          &lt;dbl&gt;
## 1       -0.148</code></pre>
<pre class="r"><code>random_dist&lt;-vector()
for(i in 1:5000){
new&lt;-data.frame(citizen=sample(citizenry_checks$citizen),checks=citizenry_checks$checks)
random_dist[i]&lt;-mean(new[new$citizen==&quot;citizens&quot;,]$checks)-
mean(new[new$citizen==&quot;noncitizens&quot;,]$checks)}
{hist(random_dist,main=&quot;&quot;,ylab=&quot;&quot;); abline(v = -0.0480556,col=&quot;red&quot;)}</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-2-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>mean(random_dist&gt;.0480556 | random_dist &lt; -.0480556)</code></pre>
<pre><code>## [1] 0.4064</code></pre>
<p><em>I first had to turn my two categories of citizenship into vectors using the values from the check numerical category. I then performed a randomization test between the citizenry groups, which I categorized into citizens and noncitizens, and checks (which ranged from 0 to 6). The null hypothesis is: mean state birth rate is the same for younger and older teens and the alternative hypothesis states that the checks are different for citizens and noncitizens. The mean difference was found to be -.1480556. I then randomized the data and created a histogram showing the results with a red line to be at the mean difference point. The red line appears on the graph because there are mean differences which are as extreme as the computed mean difference value. A t-test was run and confirmed this by showing p-value of 0.456, meaning we cannot reject the null hypothesis to say that there is a difference in checks between the two type of citizenship.</em></p>
<ul>
<li><strong>3. (40 pts)</strong> Build a linear regression model predicting one of your response variables from at least 2 other variables, including their interaction. Mean-center any numeric variables involved in the interaction.</li>
</ul>
<pre class="r"><code>Arrests$age_c &lt;- Arrests$age - mean(Arrests$age)
Arrests$checks_c &lt;- Arrests$checks - mean(Arrests$checks)
fit&lt;-lm(checks_c~age_c*employed, data= Arrests)
summary(fit)</code></pre>
<pre><code>##
## Call:
## lm(formula = checks_c ~ age_c * employed, data =
Arrests)
##
## Residuals:
## Min 1Q Median 3Q Max
## -2.6884 -1.3206 -0.3104 1.2939 4.6567
##
## Coefficients:
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 0.695823 0.045418 15.321 &lt;2e-16 ***
## age_c 0.011812 0.005035 2.346 0.0190 *
## employedYes -0.879057 0.050995 -17.238 &lt;2e-16 ***
## age_c:employedYes 0.010864 0.005790 1.876 0.0606 .
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Residual standard error: 1.484 on 5222 degrees of
freedom
## Multiple R-squared: 0.07118, Adjusted R-squared: 0.07064
## F-statistic: 133.4 on 3 and 5222 DF, p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>t.test(data=Arrests,age_c~employed,var.eq=T)</code></pre>
<pre><code>##
## Two Sample t-test
##
## data: age_c by employed
## t = 8.4908, df = 5224, p-value &lt; 2.2e-16
## alternative hypothesis: true difference in means is not
equal to 0
## 95 percent confidence interval:
## 1.821362 2.914913
## sample estimates:
## mean in group No mean in group Yes
## 1.8628805 -0.5052571</code></pre>
<pre class="r"><code>ggplot(Arrests, aes(x=age_c, y=checks_c, group=employed)) + geom_point(aes(color = employed)) + geom_smooth(method = &quot;lm&quot;, formula = y~1,se=F,fullrange = T,aes(color = employed)) + theme(legend.position = c(.945,.91)) + xlab(&quot;Age_C&quot;)</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-3-1.png" width="768" style="display: block; margin: auto;" />
<em>For the linear regression, I tried to predict the number of checks based on the age and employment status of the individuals, as well as the interaction between the variables. The linear regression showed that the effect of age and employment individually have a significant effect on the check number (p values of .0190 and 2x10^-16 respectively), but when considered together their significance is no longer there. The results conclude that for every one year of age increased, the number of checks increases by .011812. Additionally, the test showed people who are employed have .879057 less checks than those who aren’t. The slope for the effect of age on checks is 0.010864 higher for employed than nonemployed.</em></p>
<pre class="r"><code>newset&lt;-Arrests
newset$age_c&lt;-mean(Arrests$age_c)
newset$mean&lt;-predict(fit,newset)
newset$age_c&lt;-mean(Arrests$age_c)+sd(Arrests$age_c)
newset$plus.sd&lt;-predict(fit,newset)
newset$age_c&lt;-mean(Arrests$age_c)-sd(Arrests$age_c)
newset$minus.sd&lt;-predict(fit,newset)

my_colors&lt;-c(&quot;#619CFF&quot;,&quot;#F8766D&quot;,&quot;#00BA38&quot;)
names(my_colors)&lt;-c(&quot;-1 sd&quot;,&quot;mean&quot;,&quot;+1 sd&quot;)
my_colors=as.factor(my_colors)

ggplot(Arrests,aes(checks_c,age_c),group=my_colors)+geom_point()+geom_line(data=newset,aes(y=mean,color=&quot;mean&quot;))+geom_line(data=newset,aes(y=plus.sd,color=&quot;+1 sd&quot;))+geom_line(data=newset,aes(y=minus.sd,color=&quot;-1 sd&quot;))+scale_color_manual(values=my_colors)+labs(color=&quot;Citizen (cont)&quot;)+theme(legend.position=c(.9,.9)) #Interaction Plot</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-4-1.png" width="768" style="display: block; margin: auto;" />
<em>When I plotted the interaction, I got this very crude plot as the result. It ended up this way due to the fact that the response variables were all in whole integers. There does not seem to be a lot of interaction going on in general between age and checks. If anything, there tends to be less older people with a high number of checks. There definitely does not appear to be a clear trend though.</em></p>
<pre class="r"><code>residuals &lt;- lm(checks_c ~ age_c*citizen, data = Arrests)$residuals
fitted &lt;- lm(checks_c ~ age_c*citizen, data = Arrests)$fitted.values
residuals &lt;- fit$residuals
fit_values &lt;- fit$fitted.values

#Checks for homoskedasticity and linearity
ggplot() + geom_point(aes(fit_values, residuals)) + geom_hline(yintercept = 0, color = &#39;orange&#39;)</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-5-1.png" width="768" style="display: block; margin: auto;" />
<em>Upon testing for homoskedacity I found the plot to be heteroskedastic and nonlinear.</em></p>
<pre class="r"><code>ggplot() + geom_qq(aes(sample=residuals)) + geom_qq_line(aes(sample = residuals, color = &quot;red&quot;))</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-6-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot()+geom_histogram(aes(residuals), bins=20) #Plot to check for normality</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-7-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ks.test(residuals, &quot;pnorm&quot;, mean=0, sd(residuals)) </code></pre>
<pre><code>## 
##  One-sample Kolmogorov-Smirnov test
## 
## data:  residuals
## D = 0.1759, p-value &lt; 2.2e-16
## alternative hypothesis: two-sided</code></pre>
<p><em>The graphs and ks.test show that the data is not normally distributed. The histogram isn’t clearly skewed one way or the other but doesn’t proportionally pan out into a bell curve. The points on the qq plot additionally do not align with the red line, meaning it is not normal. The ks test resulted in a p value much smaller than .05, meaning it is significantly not normal. As a result we reject the null that says my data is normal.</em></p>
<pre class="r"><code>robust &lt;- lm(checks_c ~ age_c*citizen, data = Arrests)
bptest(robust)</code></pre>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  robust
## BP = 18.04, df = 3, p-value = 0.0004315</code></pre>
<pre class="r"><code>summary(robust)$coef[,1:2]</code></pre>
<pre><code>##                      Estimate  Std. Error
## (Intercept)       0.099410179 0.055628493
## age_c             0.018445386 0.006097038
## citizenYes       -0.114718392 0.060141436
## age_c:citizenYes  0.007539949 0.006708677</code></pre>
<pre class="r"><code>coeftest(robust, vcov = vcovHC(robust))[,1:2]</code></pre>
<pre><code>##                      Estimate  Std. Error
## (Intercept)       0.099410179 0.059550344
## age_c             0.018445386 0.006096651
## citizenYes       -0.114718392 0.063702274
## age_c:citizenYes  0.007539949 0.006691445</code></pre>
<pre class="r"><code>(sum((Arrests$checks_c - mean(Arrests$checks_c))^2) - sum(fit$residuals^2)) / sum((Arrests$checks_c - mean(Arrests$checks_c))^2)</code></pre>
<pre><code>## [1] 0.07117571</code></pre>
<p><em>The results of the BP test gave a p value of less than 0.05, so null hypothesis can be rejected. This means that my data is heteroskedastic. When using the robust standard error, the standard error of the intercept and citizenship increased while the standard error for age and the interaction between age and citizenship decreased. My model explain 7.12% of variation.</em></p>
<pre><code>- Interpret the coefficient estimates (do not discuss significance) (10)
- Plot the regression using `ggplot()` using geom_smooth(method=&quot;lm&quot;). If your interaction is numeric by numeric, refer to code in the slides to make the plot or check out the `interactions` package, which makes this easier. If you have 3 or more predictors, just chose two of them to plot for convenience. (10)
- What proportion of the variation in the outcome does your model explain? (4)
- Check assumptions of linearity, normality, and homoskedasticity either graphically or using a hypothesis test (5)
- Regardless, recompute regression results with robust standard errors via `coeftest(..., vcov=vcovHC(...))`. Discuss significance of results, including any changes from before/after robust SEs if applicable. (10)</code></pre>
<ul>
<li><strong>4. (5 pts)</strong> Rerun same regression model (with the interaction), but this time compute bootstrapped standard errors (either by resampling observations or residuals). Discuss any changes you observe in SEs and p-values using these SEs compared to the original SEs and the robust SEs)</li>
</ul>
<pre class="r"><code>set.seed(123)

bootstrapdata &lt;- sample_frac(Arrests, replace=T)
sampledist &lt;- replicate(5000, {
bootstrapdata &lt;- sample_frac(Arrests, replace=T)
bootstrapfitted &lt;- lm(checks_c ~ age_c*citizen, data = bootstrapdata)
coef(bootstrapfitted)
})
sampledist %&gt;% t %&gt;% as.data.frame %&gt;% summarize_all(sd)</code></pre>
<pre><code>##   (Intercept)       age_c citizenYes age_c:citizenYes
## 1   0.0590742 0.006080104 0.06334151      0.006671113</code></pre>
<p><em>The bootstrapped standard errors were .0590742 for the intercept, .006080104 for age, .06334151 for citizens, and .006671113 for the interaction between age and the being a citizen. All of these standard errors appear to be close to but slightly less than the robust errors. However, due to the fact that they have such similar numbers, the bootstrap standard errors will likely have a p-value of less than 0.05 just like the robust standard errors. The original standard errors were .055628493 for the intercept, .006097038 for the age, .060141436 for citizens, and .006708677 for the interaction. These standard errors are all similar to the bootstrap standard errors that were just found.</em></p>
<ul>
<li><strong>5. (30 pts)</strong> Fit a logistic regression model predicting a binary variable (if you don’t have one, make/get one) from at least two explanatory variables (interaction not necessary).</li>
</ul>
<pre class="r"><code>#logistic regression
Arrests&lt;-Arrests%&gt;%mutate(CitizenStatus=ifelse(citizen==&quot;Yes&quot;,0,1))
head(Arrests)</code></pre>
<pre><code>## X released colour year age sex employed citizen checks
age_c checks_c CitizenStatus
## 1 1 Yes White 2002 21 Male Yes Yes 3 -2.8465365
1.3635668 0
## 2 2 No Black 1999 17 Male Yes Yes 3 -6.8465365 1.3635668
0
## 3 3 Yes White 2000 24 Male Yes Yes 3 0.1534635 1.3635668
0
## 4 4 No Black 2000 46 Male Yes Yes 1 22.1534635
-0.6364332 0
## 5 5 Yes Black 1999 27 Female Yes Yes 1 3.1534635
-0.6364332 0
## 6 6 Yes Black 1998 16 Female Yes Yes 0 -7.8465365
-1.6364332 0</code></pre>
<pre class="r"><code>fit_3 &lt;- glm(CitizenStatus~age+checks,data=Arrests,family = &quot;binomial&quot;)
coeftest(fit_3)</code></pre>
<pre><code>##
## z test of coefficients:
##
## Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) -2.3578867 0.1190337 -19.8086 &lt; 2.2e-16 ***
## age 0.0215454 0.0043689 4.9315 8.159e-07 ***
## checks 0.0461086 0.0254307 1.8131 0.06981 .
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>exp(coef(fit_3))</code></pre>
<pre><code>## (Intercept)         age      checks 
##  0.09461998  1.02177917  1.04718814</code></pre>
<p><em>The coefficient estimates for my regression are: -2.3578867 for the intercept, .0215454 for age, and .0461086 for the checks and age and the intercept are both significant with a p value of less than .05. This means that you fail to reject the null hypothesis for checks having a significant relationship with citizenship status. There is however a significant relationship between age and citizenship, and you can reject the null for that observation.</em></p>
<pre class="r"><code>prob &lt;- predict(fit_3, type = &quot;response&quot;)
predict &lt;- ifelse(prob &gt; .5, 1, 0)
table(prediction = predict, truth = Arrests$CitizenStatus) %&gt;% addmargins()</code></pre>
<pre><code>##           truth
## prediction    0    1  Sum
##        0   4455  771 5226
##        Sum 4455  771 5226</code></pre>
<p><em>The accuracy, TPR, TNR, and PPV for my model are unable to be calculated as R is giving me an incomplete confusion matrix. I wish I could calculate them but I have tried everything and I still cannot get it to work.</em></p>
<pre class="r"><code>Arrests$logit&lt;-predict(fit_3,type=&quot;link&quot;)
ggplot(Arrests,aes(logit, fill=as.factor(citizen)))+geom_density(alpha=.3)+
  theme(legend.position=c(.63,.85))+geom_vline(xintercept=0)+xlab(&quot;predictor (logit)&quot;)</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-13-1.png" width="768" style="display: block; margin: auto;" />
<em>The density plot created is extremely overlapped, meaning the model is not very good at categorizing people by citizenship.</em></p>
<pre class="r"><code>ROCplot&lt;-ggplot(Arrests)+geom_roc(aes(d=CitizenStatus,m=prob), n.cuts=0) 
ROCplot</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-14-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>calc_auc(ROCplot)</code></pre>
<pre><code>##   PANEL group       AUC
## 1     1    -1 0.5615568</code></pre>
<p><em>The ROC plot has an AUC of 0.5615568, which is right around 0.5. This is a horrible AUC and corresponds with the density plot. This is indicative of a poor model that will likely incorrectly categorize an individual into the wrong citizenship status.</em></p>
<pre class="r"><code>class_diag &lt;- function(probs, truth){

tab &lt;- table(factor(probs &gt; .5, levels=c(&quot;FALSE&quot;, &quot;TRUE&quot;)), truth)
acc = sum(diag(tab)) / sum(tab)
sens=tab[2,2]/colSums(tab)[2]
spec=tab[1,1]/colSums(tab)[1]
ppv=tab[2,2]/rowSums(tab)[2]
if(is.numeric(truth)==FALSE &amp; is.logical(truth)==FALSE) truth&lt;-as.numeric(truth)-1

ord&lt;-order(probs, decreasing=TRUE)
probs &lt;- probs[ord]; truth &lt;- truth[ord]
TPR=cumsum(truth)/max(1,sum(truth))
FPR=cumsum(!truth)/max(1,sum(!truth))
dup&lt;-c(probs[-1]&gt;=probs[-length(probs)], FALSE)
TPR&lt;-c(0,TPR[!dup],1); FPR&lt;-c(0,FPR[!dup],1)
n &lt;- length(TPR)
auc&lt;- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )
data.frame(acc,sens,spec,ppv,auc)
} 

class_diag(prob, Arrests$CitizenStatus)</code></pre>
<pre><code>##         acc sens spec ppv       auc
## 1 0.8524684    0    1 NaN 0.5615568</code></pre>
<pre class="r"><code>set.seed(123)
k=10 
tenfolddata &lt;- Arrests[sample(nrow(Arrests)), ] 
folds &lt;- cut(seq(1:nrow(Arrests)), breaks=k, labels = F)
diags &lt;- NULL
for(i in 1:k){
train &lt;- tenfolddata[folds!=i, ]
test &lt;- tenfolddata[folds==i, ]
truth &lt;- test$CitizenStatus

fit8 &lt;- glm(CitizenStatus ~ age + checks, data = train, family = &quot;binomial&quot;)
probs &lt;- predict(fit8, newdata = test, type=&quot;response&quot;)
diags &lt;- rbind(diags, class_diag(probs, truth))
}

summarize_all(diags,mean)</code></pre>
<pre><code>##         acc sens spec ppv       auc
## 1 0.8524728    0    1 NaN 0.5590668</code></pre>
<p><em>The 10-fold CV returned 0.8524728 for accuracy, 0 for sensitivity, and 1 for specificity. The AUC was 0.5590668. I’m assuming the sensitivity is 0 for the same reason my confusion matrix was messed up. Additionally that is probably why precision was NaN on the output.</em></p>
<pre><code>- Interpret coefficient estimates in context (10)
- Report a confusion matrix for your logistic regression (5)
- Compute and discuss the Accuracy, Sensitivity (TPR), Specificity (TNR), Precision (PPV), and AUC of your model (5)
- Using ggplot, make a density plot of the log-odds (logit) colored/grouped by your binary outcome variable (5)
- Generate an ROC curve (plot) and calculate AUC (either manually or with a package); interpret (5)</code></pre>
<ul>
<li><strong>6. (25 pts)</strong> Perform a logistic regression predicting the same binary response variable from <em>ALL</em> of the rest of your variables (the more, the better!)</li>
</ul>
<pre class="r"><code>Arrests2 &lt;- Arrests %&gt;% select(-checks_c, -age_c, -logit, -citizen)
head(Arrests2)</code></pre>
<pre><code>## X released colour year age sex employed checks
CitizenStatus
## 1 1 Yes White 2002 21 Male Yes 3 0
## 2 2 No Black 1999 17 Male Yes 3 0
## 3 3 Yes White 2000 24 Male Yes 3 0
## 4 4 No Black 2000 46 Male Yes 1 0
## 5 5 Yes Black 1999 27 Female Yes 1 0
## 6 6 Yes Black 1998 16 Female Yes 0 0</code></pre>
<pre class="r"><code>y&lt;-as.matrix(Arrests2$CitizenStatus) #grab response
x&lt;-model.matrix(CitizenStatus~.,data=Arrests2)[,-1] #grab predictors
x&lt;-scale(x)
cv&lt;-cv.glmnet(x,y)
lasso&lt;-glmnet(x,y,family=&quot;binomial&quot;,lambda=cv$lambda.1se)
coef(lasso)</code></pre>
<pre><code>## 9 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                      s0
## (Intercept) -1.92527845
## X            .         
## releasedYes -0.05107807
## colourWhite -0.40058408
## year        -0.57430580
## age          .         
## sexMale      .         
## employedYes  .         
## checks       .</code></pre>
<pre class="r"><code>class_diag(prob,Arrests2$CitizenStatus)</code></pre>
<pre><code>##         acc sens spec ppv       auc
## 1 0.8524684    0    1 NaN 0.5615568</code></pre>
<pre class="r"><code>set.seed(1234)
k=10 #choose number of folds
data&lt;-Arrests2[sample(nrow(Arrests2)),] #randomly order rows
folds&lt;-cut(seq(1:nrow(Arrests2)),breaks=k,labels=F) #create folds
diags&lt;-NULL
for(i in 1:k){
## Create training and test sets
train&lt;-data[folds!=i,]
test&lt;-data[folds==i,]
truth&lt;-test$CitizenStatus ## Truth labels for fold i
## Train model on training set (all but fold i)
fit6&lt;-glm(CitizenStatus~.,data=train,family=&quot;binomial&quot;)
## Test model on test set (fold i)
probs&lt;-predict(fit6,newdata = test,type=&quot;response&quot;)
## Get diagnostics for fold i
diags&lt;-rbind(diags,class_diag(probs,truth))
}

summarize_all(diags,mean)</code></pre>
<pre><code>##         acc      sens      spec       ppv       auc
## 1 0.8606954 0.1569379 0.9824965 0.6168605 0.7672823</code></pre>
<p><em>Based on the output, age is the most predictive variable, however it is still extremely lousy at it. A lot of the variables had negative numbers as outputs which I thought was strange. The results of my CV are the exact same as the logistic regression.</em></p>
<pre><code>- Fit model, compute in-sample classification diagnostics (Accuracy, Sensitivity, Specificity, Precision, AUC), and interpret (5)
- Perform 10-fold (or repeated random sub-sampling) CV with the same model and report average out-of-sample classification diagnostics (Accuracy, Sensitivity, Specificity, Precision, and AUC); interpret AUC and compare with the in-sample metrics (10)
- Perform LASSO on the same model/variables. Choose lambda to give the simplest model whose accuracy is near that of the best (i.e., `lambda.1se`). Discuss which variables are retained. (5)
- Perform 10-fold CV using only the variables lasso selected: compare model&#39;s out-of-sample AUC to that of your logistic regressions above (5)</code></pre>
</div>

            
        <hr>         <div class="related-posts">
                <h5>Related Posts</h5>
                
              </div> 
            </div>
          </div>

   <hr>  <div class="disqus">
  <div id="disqus_thread"></div>
  <script type="text/javascript">

    (function() {
      
      
      if (window.location.hostname == "localhost")
        return;

      var disqus_shortname = '';
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div> 
        </div>
      </div>
    </div>

    
    <footer>
  <div id="footer">
    <div class="container">
      <p class="text-muted">&copy; All rights reserved. Powered by <a href="https://gohugo.io/">Hugo</a> and
      <a href="http://www.github.com/nurlansu/hugo-sustain/">sustain</a> with ♥</p>
    </div>
  </div>
</footer>
<div class="footer"></div>


<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script src="../../js/docs.min.js"></script>
<script src="../../js/main.js"></script>

<script src="../../js/ie10-viewport-bug-workaround.js"></script>


    
  </body>
</html>
